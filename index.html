<!DOCTYPE html>
<html lang="fr">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Assistant Vocal OpenAI</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            display: flex;
            justify-content: center;
            align-items: center;
            height: 100vh;
            margin: 0;
            background-color: #f0f2f5;
        }
        .container {
            text-align: center;
            padding: 2rem;
            background: white;
            border-radius: 1rem;
            box-shadow: 0 4px 6px rgba(0,0,0,0.1);
        }
        button {
            padding: 1rem 2rem;
            font-size: 1.2rem;
            background-color: #10a37f;
            color: white;
            border: none;
            border-radius: 0.5rem;
            cursor: pointer;
            transition: all 0.3s;
        }
        button:hover {
            background-color: #0d8a6a;
        }
        button:disabled {
            background-color: #cccccc;
            cursor: not-allowed;
        }
        .status {
            margin-top: 1.5rem;
            font-size: 1.1rem;
            color: #666;
        }
    </style>
</head>
<body>
    <div class="container">
        <button id="startBtn">ðŸŽ¤ Activer le Micro</button>
        <div id="status" class="status">PrÃªt Ã  Ã©couter</div>
    </div>

    <script>
        // ================= CONFIGURATION =================
        const OPENAI_API_KEY = "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";
        
        const SYSTEM_PROMPT = `
        Tu es un assistant vocal qui rÃ©pond uniquement par voix. 
        Tu vends un appareil photo Nikon D750 sur Le Bon Coin.
        Prix: 500â‚¬ (nÃ©gociable Ã  450â‚¬ minimum).
        Ã‰tat: excellent, 15 000 dÃ©clenchements.
        Accessoires: 2 batteries, chargeur, sac.
        Sois bref, courtois et naturel dans tes rÃ©ponses vocales.
        `;
        // ================================================

        // Ã‰lÃ©ments UI
        const startBtn = document.getElementById('startBtn');
        const statusEl = document.getElementById('status');

        // VÃ©rification compatibilitÃ©
        if (!('webkitSpeechRecognition' in window)) {
            statusEl.textContent = "Navigateur non supportÃ© (utilisez Chrome/Edge)";
            startBtn.disabled = true;
        }

        // Initialisation reconnaissance vocale
        const recognition = new (window.SpeechRecognition || window.webkitSpeechRecognition)();
        recognition.continuous = true;
        recognition.interimResults = false;
        recognition.lang = 'fr-FR';

        // Gestion de l'Ã©tat
        let isListening = false;

        // DÃ©marrer l'Ã©coute
        function startListening() {
            try {
                recognition.start();
                isListening = true;
                startBtn.disabled = true;
                statusEl.textContent = "Ã‰coute en cours... Parlez maintenant";
            } catch (error) {
                statusEl.textContent = "Erreur: " + error.message;
            }
        }

        // ArrÃªter l'Ã©coute
        function stopListening() {
            recognition.stop();
            isListening = false;
            startBtn.disabled = false;
            statusEl.textContent = "PrÃªt Ã  Ã©couter";
        }

        // SynthÃ¨se vocale avec streaming
        function speakStream(textStream) {
            const utteranceQueue = [];
            let currentUtterance = null;

            const processQueue = () => {
                if (currentUtterance === null && utteranceQueue.length > 0) {
                    currentUtterance = utteranceQueue.shift();
                    const speech = new SpeechSynthesisUtterance(currentUtterance);
                    speech.lang = 'fr-FR';
                    speech.rate = 1.0;

                    speech.onend = () => {
                        currentUtterance = null;
                        processQueue();
                    };

                    window.speechSynthesis.speak(speech);
                }
            };

            const addTextToQueue = (text) => {
                utteranceQueue.push(text);
                processQueue();
            };

            return { addTextToQueue };
        }

        // Envoyer Ã  l'API OpenAI avec streaming
        async function queryOpenAI(userInput) {
            try {
                statusEl.textContent = "L'IA rÃ©flÃ©chit...";
                
                const response = await fetch('https://api.openai.com/v1/chat/completions', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json',
                        'Authorization': `Bearer ${OPENAI_API_KEY}`
                    },
                    body: JSON.stringify({
                        model: "gpt-4-turbo",
                        messages: [
                            { role: "system", content: SYSTEM_PROMPT },
                            { role: "user", content: userInput }
                        ],
                        temperature: 0.7,
                        max_tokens: 100,
                        stream: true // Activer le streaming
                    })
                });

                if (!response.ok) {
                    throw new Error(`Erreur HTTP: ${response.status}`);
                }

                const reader = response.body.getReader();
                const decoder = new TextDecoder();
                let partialResponse = '';

                const streamer = speakStream();

                while (true) {
                    const { done, value } = await reader.read();
                    if (done) break;

                    const chunk = decoder.decode(value, { stream: true });
                    const lines = chunk.split('\n').filter(line => line.trim().startsWith('data: '));

                    for (const line of lines) {
                        const data = line.replace('data: ', '');
                        if (data === '[DONE]') continue;

                        try {
                            const json = JSON.parse(data);
                            const content = json.choices[0]?.delta?.content || '';
                            partialResponse += content;

                            // Ajouter le texte au stream de synthÃ¨se vocale
                            if (content) {
                                streamer.addTextToQueue(content);
                            }
                        } catch (error) {
                            console.error("Erreur parsing JSON:", error);
                        }
                    }
                }

                return partialResponse;

            } catch (error) {
                console.error("Erreur OpenAI:", error);
                return "DÃ©solÃ©, une erreur technique s'est produite. Veuillez rÃ©essayer.";
            }
        }

        // Ã‰vÃ©nements
        startBtn.addEventListener('click', startListening);

        recognition.onresult = async (event) => {
            const userInput = event.results[event.results.length - 1][0].transcript;
            
            // Obtenir la rÃ©ponse de l'IA
            await queryOpenAI(userInput);
        };

        recognition.onerror = (event) => {
            console.error("Erreur reconnaissance:", event.error);
            statusEl.textContent = "Erreur: " + event.error;
            stopListening();
        };

        recognition.onend = () => {
            if (isListening) {
                recognition.start();
            }
        };
    </script>
</body>
</html>
